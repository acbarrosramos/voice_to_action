{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyOzaxp/psbxCnxovNX3pRSB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"005e9c1feccc4fb2af8c10d11d4b29d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bff6ea3fa3da4280a4b3798258cc9186","IPY_MODEL_e2a147563fda472b8a799bee74cff4b0","IPY_MODEL_5c33f8def7604404be68aa38b4c4e6d5"],"layout":"IPY_MODEL_af7fe5feadbc47f9ab0e17258b8dfa0c"}},"bff6ea3fa3da4280a4b3798258cc9186":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3154ab0562d64810bc9820959780d0ad","placeholder":"​","style":"IPY_MODEL_49ebe05a2f3340adbd1ec72f536e6a68","value":"config.json: 100%"}},"e2a147563fda472b8a799bee74cff4b0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c18f3631aaa44e44b8538b7239cb4688","max":1294,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e1c4ac992494837a878d8a438e1d5d5","value":1294}},"5c33f8def7604404be68aa38b4c4e6d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa043965a562429393630885462e4868","placeholder":"​","style":"IPY_MODEL_ad7c5355257d46699b586bf3ad51ae02","value":" 1.29k/1.29k [00:00&lt;00:00, 97.1kB/s]"}},"af7fe5feadbc47f9ab0e17258b8dfa0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3154ab0562d64810bc9820959780d0ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49ebe05a2f3340adbd1ec72f536e6a68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c18f3631aaa44e44b8538b7239cb4688":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e1c4ac992494837a878d8a438e1d5d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa043965a562429393630885462e4868":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad7c5355257d46699b586bf3ad51ae02":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a6e75453aeb4d6da17d2a8b1f46b866":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a325b40e6906467ead4c63ef88ff2a77","IPY_MODEL_ce6cac752ae74ec990e4ddcf71d64aaf","IPY_MODEL_2eb6da61f69949f2817bfa4ff40c1fe3"],"layout":"IPY_MODEL_bf9e8fe4d07840ad900a8530fa61fddc"}},"a325b40e6906467ead4c63ef88ff2a77":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8a51cdd579f4732be9d56a98061af84","placeholder":"​","style":"IPY_MODEL_7a87ab1aed3c4f0e8f753ae583ec4875","value":"pytorch_model.bin: 100%"}},"ce6cac752ae74ec990e4ddcf71d64aaf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_562002d2ceb94d42bc9a54105ba55a26","max":1262120663,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4fcfd289c30144c09636a145cd621108","value":1262120663}},"2eb6da61f69949f2817bfa4ff40c1fe3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1e91acdc1354d87b3879066079b87a2","placeholder":"​","style":"IPY_MODEL_c04139c4fa0641a993a730e2b8785e00","value":" 1.26G/1.26G [00:04&lt;00:00, 322MB/s]"}},"bf9e8fe4d07840ad900a8530fa61fddc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8a51cdd579f4732be9d56a98061af84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a87ab1aed3c4f0e8f753ae583ec4875":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"562002d2ceb94d42bc9a54105ba55a26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fcfd289c30144c09636a145cd621108":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f1e91acdc1354d87b3879066079b87a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c04139c4fa0641a993a730e2b8785e00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"ha0gZR8ZwYMM"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c114ly-rNSxr","executionInfo":{"status":"ok","timestamp":1717547740050,"user_tz":180,"elapsed":130614,"user":{"displayName":"Ana Carolina Barros Ramos","userId":"13918483350280573457"}},"outputId":"94d85c44-0727-463f-f731-96699b9c3d76"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n","Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.3.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (4.12.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0->torchaudio)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0->torchaudio)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0->torchaudio)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0->torchaudio)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0->torchaudio)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0->torchaudio)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0->torchaudio)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0->torchaudio)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0->torchaudio)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0->torchaudio)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0->torchaudio)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->torchaudio)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0->torchaudio) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0->torchaudio) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","!pip install transformers\n","!pip install torchaudio"]},{"cell_type":"code","source":["!pip install pydub"],"metadata":{"id":"SSfP62UkOGFJ","executionInfo":{"status":"ok","timestamp":1717547745630,"user_tz":180,"elapsed":5585,"user":{"displayName":"Ana Carolina Barros Ramos","userId":"13918483350280573457"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2d30eb16-50c8-4424-ffa6-e7838b2258ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub\n","Successfully installed pydub-0.25.1\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Carregar o dataset\n","dataset_path = '/content/gdrive/My Drive/Colab Notebooks/audios/dataset.csv'\n","data = pd.read_csv(dataset_path)\n","\n","# Corrigindo os caminhos na coluna 'Location'\n","data['Location'] = data['Location'].str.replace('/content/drive', '/content/gdrive', regex=False)\n","\n","# Verificar se o replace foi bem sucedido\n","print(data['Location'].head())\n","\n","# Salvar o dataframe corrigido, se necessário\n","data.to_csv(dataset_path, index=False)"],"metadata":{"id":"RyKWv1b_N8-b","executionInfo":{"status":"ok","timestamp":1717547746466,"user_tz":180,"elapsed":839,"user":{"displayName":"Ana Carolina Barros Ramos","userId":"13918483350280573457"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2644effd-6fc7-468e-bbba-81f0334a6efb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0    /content/gdrive/My Drive/Colab Notebooks/audio...\n","1    /content/gdrive/My Drive/Colab Notebooks/audio...\n","2    /content/gdrive/My Drive/Colab Notebooks/audio...\n","3    /content/gdrive/My Drive/Colab Notebooks/audio...\n","4    /content/gdrive/My Drive/Colab Notebooks/audio...\n","Name: Location, dtype: object\n"]}]},{"cell_type":"code","source":["from pydub import AudioSegment\n","import numpy as np\n","import torch\n","\n","def load_and_preprocess_audio(audio_path):\n","    # Carrega o áudio com pydub, que suporta diversos formatos\n","    audio = AudioSegment.from_file(audio_path)\n","    # Converte para um array de onda de áudio do tipo numpy\n","    samples = np.array(audio.get_array_of_samples())\n","    # Se o áudio for estéreo, converte para mono\n","    if audio.channels == 2:\n","        samples = samples.reshape((-1, 2)).mean(axis=1)\n","    waveform = torch.tensor(samples).float() / 2**15  # Conversão para tensor e normalização\n","    waveform = waveform.unsqueeze(0)  # Adiciona uma dimensão de canal\n","    sample_rate = audio.frame_rate  # Obter a taxa de amostragem\n","    return waveform, sample_rate\n","\n","# Exemplo de carregamento de um arquivo de áudio\n","waveform, sample_rate = load_and_preprocess_audio(data['Location'][0])"],"metadata":{"id":"45frQT5xOH2C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Aqui começa o fine tune\n","\n","### **1. Preparando DataLoaders**"],"metadata":{"id":"4FP43Xmoukxe"}},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","import torchaudio\n","import torch\n","from torch.nn.utils.rnn import pad_sequence\n","from sklearn.model_selection import train_test_split\n","\n","# Divisão do dataset em treino e validação\n","train_df, val_df = train_test_split(data, test_size=0.2, random_state=42)\n","\n","class AudioDataset(Dataset):\n","    def __init__(self, dataframe, label_mapping):\n","        self.dataframe = dataframe\n","        self.label_mapping = label_mapping\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx):\n","        audio_path = self.dataframe.iloc[idx]['Location']\n","        sentiment = self.dataframe.iloc[idx]['Sentiment']\n","        label = self.label_mapping[sentiment]\n","        waveform, sample_rate = load_and_preprocess_audio(audio_path)\n","        return waveform.squeeze(0), label\n","\n","    @staticmethod\n","    def collate_fn(batch):\n","        waveforms, labels = zip(*batch)\n","        waveforms_padded = pad_sequence(waveforms, batch_first=True, padding_value=0.0)\n","        labels_tensor = torch.tensor(labels, dtype=torch.long)\n","        return waveforms_padded, labels_tensor\n","\n","# Mapeamento de sentimentos para inteiros\n","label_mapping = {'positive': 0, 'negative': 1, 'neutral': 2}\n","\n","# Instâncias do dataset\n","train_dataset = AudioDataset(train_df, label_mapping)\n","val_dataset = AudioDataset(val_df, label_mapping)\n","\n","# DataLoaders\n","train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=AudioDataset.collate_fn)\n","val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=AudioDataset.collate_fn)"],"metadata":{"id":"BIdyAL7GmuQF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2. **Definição do Modelo e Função de Perda** [OPÇÃO 1]\n","\n","> Add blockquote\n","\n"],"metadata":{"id":"_FrOfzGWOf9v"}},{"cell_type":"code","source":["## OFICIAL\n","\n","# #esse funciona\n","\n","# from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2Config\n","# import torch.nn as nn\n","\n","# # Carregando a configuração com número apropriado de labels\n","# config = Wav2Vec2Config.from_pretrained(\"facebook/wav2vec2-base-960h\", num_labels=3)\n","\n","# # Carregando o modelo com configuração ajustada para classificação\n","# model = Wav2Vec2ForSequenceClassification.from_pretrained(\"facebook/wav2vec2-base-960h\", config=config)\n","# model.to('cuda')  # Transferindo modelo para GPU\n","\n","# # Você pode continuar usando CrossEntropyLoss com este modelo\n","# criterion = nn.CrossEntropyLoss().to('cuda')"],"metadata":{"id":"J_ur3fZoObBA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def train_model(model, train_loader, criterion, optimizer, epochs):\n","#     model.train()\n","#     for epoch in range(epochs):\n","#         total_loss = 0\n","#         for waveforms, labels in train_loader:\n","#             waveforms = waveforms.to('cuda')\n","#             labels = labels.to('cuda')\n","\n","#             optimizer.zero_grad()\n","\n","#             outputs = model(waveforms).logits  # Saída do modelo\n","#             outputs = torch.nn.functional.log_softmax(outputs, dim=-1)\n","\n","#             # Calcular a perda\n","#             loss = criterion(outputs, labels)\n","#             loss.backward()\n","#             optimizer.step()\n","\n","#             total_loss += loss.item()\n","\n","#         print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader)}\")"],"metadata":{"id":"6FndwRbQOk7a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2. **Definição do Modelo e Função de Perda** [OPÇÃO 1]\n"],"metadata":{"id":"kjJ_V8t_y8W4"}},{"cell_type":"code","source":["#teste\n","from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2Config\n","import torch.nn as nn\n","\n","config = Wav2Vec2Config.from_pretrained(\"facebook/wav2vec2-large-xlsr-53-portuguese\", num_labels=3)\n","model = Wav2Vec2ForSequenceClassification.from_pretrained(\"facebook/wav2vec2-large-xlsr-53-portuguese\", config=config)\n","\n","model.to('cuda')  # Transferindo modelo para GPU\n","\n","# # Você pode continuar usando CrossEntropyLoss com este modelo\n","criterion = nn.CrossEntropyLoss().to('cuda')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275,"referenced_widgets":["005e9c1feccc4fb2af8c10d11d4b29d0","bff6ea3fa3da4280a4b3798258cc9186","e2a147563fda472b8a799bee74cff4b0","5c33f8def7604404be68aa38b4c4e6d5","af7fe5feadbc47f9ab0e17258b8dfa0c","3154ab0562d64810bc9820959780d0ad","49ebe05a2f3340adbd1ec72f536e6a68","c18f3631aaa44e44b8538b7239cb4688","4e1c4ac992494837a878d8a438e1d5d5","fa043965a562429393630885462e4868","ad7c5355257d46699b586bf3ad51ae02","7a6e75453aeb4d6da17d2a8b1f46b866","a325b40e6906467ead4c63ef88ff2a77","ce6cac752ae74ec990e4ddcf71d64aaf","2eb6da61f69949f2817bfa4ff40c1fe3","bf9e8fe4d07840ad900a8530fa61fddc","f8a51cdd579f4732be9d56a98061af84","7a87ab1aed3c4f0e8f753ae583ec4875","562002d2ceb94d42bc9a54105ba55a26","4fcfd289c30144c09636a145cd621108","f1e91acdc1354d87b3879066079b87a2","c04139c4fa0641a993a730e2b8785e00"]},"id":"u5Lz9hY5uBFq","executionInfo":{"status":"ok","timestamp":1717547759981,"user_tz":180,"elapsed":11028,"user":{"displayName":"Ana Carolina Barros Ramos","userId":"13918483350280573457"}},"outputId":"0e58bda3-0a36-453d-bf3b-f70f5d8de1db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"005e9c1feccc4fb2af8c10d11d4b29d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/1.26G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a6e75453aeb4d6da17d2a8b1f46b866"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53-portuguese and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["def train_model(model, train_loader, criterion, optimizer, epochs):\n","    model.train()\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for waveforms, labels in train_loader:\n","            waveforms = waveforms.to('cuda')\n","            labels = labels.to('cuda')\n","\n","            optimizer.zero_grad()\n","\n","            outputs = model(waveforms).logits  # Ajuste aqui\n","            loss = criterion(outputs, labels)  # Sem softmax/log_softmax\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += loss.item()\n","\n","        print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader)}\")"],"metadata":{"id":"DcRsgBIoy4iK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Rodando o fine-tune ##"],"metadata":{"id":"4yE5-qvTzDPY"}},{"cell_type":"code","source":["import torch.optim as optim\n","\n","# Configuração do otimizador Adam\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","epochs = 10\n","\n","train_model(model, train_loader, criterion, optimizer, epochs)"],"metadata":{"id":"WXRpiRQxO5m9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717550751482,"user_tz":180,"elapsed":1699881,"user":{"displayName":"Ana Carolina Barros Ramos","userId":"13918483350280573457"}},"outputId":"cfcb6cd2-17c3-412f-8d6a-7884553eb2e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: Loss = 1.1169581974382365\n","Epoch 2: Loss = 1.106603939672966\n","Epoch 3: Loss = 1.1250473007614359\n","Epoch 4: Loss = 1.1327493637719195\n","Epoch 5: Loss = 1.101901147173438\n","Epoch 6: Loss = 1.096873396918887\n","Epoch 7: Loss = 1.0981731993374808\n","Epoch 8: Loss = 1.099005447857546\n","Epoch 9: Loss = 1.108064667427496\n","Epoch 10: Loss = 1.1034198328033908\n"]}]},{"cell_type":"markdown","source":["### 3.**Validação**"],"metadata":{"id":"vuDK7NR4O_aJ"}},{"cell_type":"code","source":["def evaluate_model(model, val_loader, criterion, device='cuda'):\n","    model.eval()  # Coloca o modelo em modo de avaliação\n","    total_loss = 0\n","    correct_predictions = 0\n","    total_predictions = 0\n","\n","    with torch.no_grad():  # Desativa a computação de gradientes\n","        for waveforms, labels in val_loader:\n","            waveforms = waveforms.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(waveforms).logits\n","            loss = criterion(outputs, labels)\n","            total_loss += loss.item()\n","\n","            _, predicted_labels = torch.max(outputs, dim=1)\n","            correct_predictions += (predicted_labels == labels).sum().item()\n","            total_predictions += labels.size(0)\n","\n","    avg_loss = total_loss / len(val_loader)\n","    accuracy = correct_predictions / total_predictions\n","    return avg_loss, accuracy\n","\n","# Uso da função\n","val_loss, val_accuracy = evaluate_model(model, val_loader, criterion)\n","print(f\"Validation Loss: {val_loss:.4f}\")\n","print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n","\n","## Primeiro modelo: com crossentropy + facebook/wav2vec2-base-960h\n","# Validation Loss: 1.1009\n","# Validation Accuracy: 0.3188\n","\n","#se não funcionar, adicionar uma cama extra no final (testar c/ Keras)"],"metadata":{"id":"PGE42JO6O8UD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717550779016,"user_tz":180,"elapsed":15139,"user":{"displayName":"Ana Carolina Barros Ramos","userId":"13918483350280573457"}},"outputId":"03b25f8f-74d9-453c-ddec-070d1649d9f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation Loss: 1.0930\n","Validation Accuracy: 0.3188\n"]}]},{"cell_type":"markdown","source":["## Resultados:\n","\n","**Primeiro modelo:** com crossentropy + facebook/wav2vec2-base-960h + 5 epochs\n","Validation Loss: 1.1009\n","Validation Accuracy: 0.3188\n","\n","**Segundo modelo:** com crossentropy + facebook/wav2vec2-xlsx-portuguese\n","Validation Loss: 1.0991\n","Validation Accuracy: 0.3188"],"metadata":{"id":"Cif6hSmu5EFN"}},{"cell_type":"code","source":["def predict_sentiment(model, audio_path, device='cuda'):\n","    waveform, sample_rate = load_and_preprocess_audio(audio_path)\n","    model.eval()\n","    waveform = waveform.to(device)\n","    with torch.no_grad():\n","        outputs = model(waveform).logits\n","        probabilities = torch.nn.functional.softmax(outputs, dim=-1)\n","        predictions = torch.argmax(probabilities, dim=-1)\n","        print(\"Raw predictions over time:\", predictions)\n","        predicted_label_index, _ = torch.mode(predictions)\n","        print(\"Most frequent predicted index:\", predicted_label_index)\n","    return predicted_label_index.item()"],"metadata":{"id":"dsuIZ814PCzD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_sentiment =  {0:'positive', 1: 'negative', 2:'neutral'}"],"metadata":{"id":"fHdTFypdPE6V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Supondo que o modelo e o label_mapping estejam carregados\n","audio_path = \"/content/gdrive/My Drive/Colab Notebooks/audios/test/carol-chorando.ogg\"\n","predicted_label_index = predict_sentiment(model, audio_path)\n","predicted_label = label_sentiment.get(predicted_label_index, \"Label not found\")\n","predicted_label"],"metadata":{"id":"Coxuyw6qPG3J","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1717548984537,"user_tz":180,"elapsed":1168,"user":{"displayName":"Ana Carolina Barros Ramos","userId":"13918483350280573457"}},"outputId":"047aaf00-2048-4ac6-d755-2a3116b3ec87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Raw predictions over time: tensor([2], device='cuda:0')\n","Most frequent predicted index: tensor(2, device='cuda:0')\n"]},{"output_type":"execute_result","data":{"text/plain":["'neutral'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":[],"metadata":{"id":"zIZ5izrOqgbD"},"execution_count":null,"outputs":[]}]}