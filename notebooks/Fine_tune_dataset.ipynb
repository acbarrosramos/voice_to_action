{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO08qPKKDQyQLNsNkhpIfiM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acbarrosramos/voice_to_action/blob/master/Fine_tune_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7N3MMLinH61",
        "outputId": "2240a528-9961-4868-b02e-c9389f40a744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from IPython.display import Audio\n",
        "drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pydub\n",
        "#!pip install SpeechRecognition"
      ],
      "metadata": {
        "id": "OQ12f44WoewF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "import speech_recognition as sr\n",
        "import io\n",
        "import os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "fdi_5vxnnN5E"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_audio(file_path):\n",
        "    recognizer = sr.Recognizer()\n",
        "    file_extension = os.path.splitext(file_path)[1][1:]\n",
        "\n",
        "    # Verifica se o arquivo já está em formato WAV, caso contrário, converte -- alguns são mp3\n",
        "    if file_extension == \"wav\":\n",
        "        audio_data = AudioSegment.from_file(file_path, format=\"wav\")\n",
        "    else:\n",
        "        audio_data = AudioSegment.from_file(file_path, format=file_extension)\n",
        "        wav_buffer = io.BytesIO()\n",
        "        audio_data.export(wav_buffer, format=\"wav\")\n",
        "        wav_buffer.seek(0)\n",
        "        audio_data = wav_buffer\n",
        "\n",
        "    # Realiza a transcrição usando o formato correto\n",
        "    if isinstance(audio_data, io.BytesIO):\n",
        "        with sr.AudioFile(audio_data) as source:\n",
        "            audio_record = recognizer.record(source)\n",
        "    else:\n",
        "        with sr.AudioFile(file_path) as source:\n",
        "            audio_record = recognizer.record(source)\n",
        "\n",
        "    try:\n",
        "        text = recognizer.recognize_google(audio_record, language='pt-BR')\n",
        "    except sr.UnknownValueError:\n",
        "        text = \"Áudio não compreendido\"\n",
        "    except sr.RequestError as e:\n",
        "        text = \"Erro ao solicitar reconhecimento de fala; {0}\".format(e)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "4qvi8muzn3Ia"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset já existente\n",
        "\n",
        "def load_existing_dataset(file_path):\n",
        "    try:\n",
        "        return pd.read_csv(file_path)\n",
        "    except FileNotFoundError:\n",
        "        return pd.DataFrame(columns=['File Name', 'Location', 'Transcription', 'Sentiment'])"
      ],
      "metadata": {
        "id": "58ddUp0utg0u"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(base_path, dataset_path):\n",
        "    existing_dataset = load_existing_dataset(dataset_path)\n",
        "    existing_files = set(existing_dataset['Location'])\n",
        "    sentiments = ['positive', 'negative', 'neutral']\n",
        "    data = []\n",
        "\n",
        "    for sentiment in sentiments:\n",
        "        folder_path = os.path.join(base_path, sentiment)\n",
        "        for filename in os.listdir(folder_path):\n",
        "            if filename.endswith((\".mp3\", \".wav\")):  # Adiciona suporte para arquivos .wav\n",
        "                file_path = os.path.join(folder_path, filename)\n",
        "                if file_path not in existing_files:\n",
        "                    transcription = transcribe_audio(file_path)\n",
        "                    data.append({\n",
        "                        'File Name': filename,\n",
        "                        'Location': file_path,\n",
        "                        'Transcription': transcription,\n",
        "                        'Sentiment': sentiment\n",
        "                    })\n",
        "                    time.sleep(1)  # Pausa de 10 segundos entre cada transcrição\n",
        "                else:\n",
        "                    existing_data = existing_dataset[existing_dataset['Location'] == file_path].iloc[0]\n",
        "                    data.append({\n",
        "                        'File Name': existing_data['File Name'],\n",
        "                        'Location': existing_data['Location'],\n",
        "                        'Transcription': existing_data['Transcription'],\n",
        "                        'Sentiment': existing_data['Sentiment']\n",
        "                    })\n",
        "\n",
        "    return pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "ZfvhTFjmqHFo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho base para os arquivos de áudio e para o dataset\n",
        "base_path = \"/content/gdrive/My Drive/Colab Notebooks/audios\"\n",
        "dataset_path = \"/content/gdrive/My Drive/Colab Notebooks/audios/dataset.csv\"\n",
        "dataset = create_dataset(base_path, dataset_path)\n",
        "dataset.to_csv(dataset_path, index=False)"
      ],
      "metadata": {
        "id": "6zN2pTlgqNb3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3FOXENniqSvO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}